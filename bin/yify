#!/usr/bin/env python

import json
import asyncio
from os import path
from math import ceil
from argparse import ArgumentParser

import aiohttp


connector = aiohttp.TCPConnector(verify_ssl=False)


@asyncio.coroutine
def query_first_page(options, parameters):
    while True:
        try:
            print("making query for the first page")
            response = yield from asyncio.wait_for(
                aiohttp.request('get', "https://yts.re/api/v2/list_movies.json",
                                params=parameters, connector=connector), options.timeout)
            if response.status == 200 and response.headers['Content-Type'] == "application/json":
                result = yield from response.json()
                status = result["status"]
                if status == "error":
                    print("error query first page: {}".format(result['error_message']))
                    continue
                elif status == "ok":
                    data = result["data"]
                    print("first page query completed, found {} movies".format(data['movie_count']))
                    return data['movie_count'], data['movies']
            else:
                print("first query got an unexpected response, retrying...")
        except asyncio.TimeoutError:
            print("retrying the first query after timeout")


@asyncio.coroutine
def query_subsequent_page(options, parameters):
    page = parameters["page"]
    print("making query for page: {}".format(page))
    response = yield from aiohttp.request('get', 'https://yts.re/api/v2/list_movies.json',
                                          params=parameters, connector=connector)
    if response.headers['Content-Type'] != "application/json":
        print("query for page #{} got an unexpected response".format(page))
        return page, None
    result = yield from response.json()
    status = result["status"]
    if status == "error":
        print("error querying page {}: {}".format(page, result['error_message']))
        return page, None
    elif status == "ok":
        data = result["data"]
        print("query for page #{} completed".format(page))
        return page, data['movies']


@asyncio.coroutine
def query_remaining_pages(pages, options, parameters):
    results = []
    while pages:
        print("{} subsequent queries to go".format(len(pages)))
        queries = []
        for page in pages:
            parameters = parameters.copy()
            parameters['page'] = page
            queries.append(query_subsequent_page(options, parameters))
        queries_done, queries_pending = yield from asyncio.wait(queries, timeout=options.timeout)
        for query in queries_done:
            page, subsequent_movie_list = query.result()
            if subsequent_movie_list is not None:
                pages.remove(page)
                results.append((page, subsequent_movie_list))
        for query in queries_pending:
            query.cancel()
    return results


@asyncio.coroutine
def fetch(options, parameters):
    movie_count, movie_list = yield from query_first_page(options, parameters)
    print("{} movies online".format(movie_count))
    pages = set(range(2, ceil(movie_count / 50) + 1))
    print("{} subsequent queries to go".format(len(pages)))
    results = yield from query_remaining_pages(pages, options, parameters)
    for page, subsequent_movie_list in sorted(results):
        print("gathering page {}".format(page))
        movie_list.extend(subsequent_movie_list)

    with open(options.database, 'w') as db:
        print("saving {} movies to local database".format(len(movie_list)))
        json.dump(movie_list, db, sort_keys=True, indent=4)


@asyncio.coroutine
def update(options, parameters):
    try:
        with open(options.database, 'r') as db:
            movie_list = json.load(db)
            movie_count = len(movie_list)
    except FileNotFoundError:
        print("local database not found, performing fetch instead of update")
        return (yield from fetch(options, parameters))

    print("{} movies in local database".format(movie_count))
    current_movie_count, current_movie_list = yield from query_first_page(options, parameters)
    print("{} movies online".format(current_movie_count))
    pages = set(range(2, ceil((current_movie_count - movie_count) / 50) + 1))
    result = yield from query_remaining_pages(pages, options, parameters)
    for page, subsequent_movie_list in sorted(result):
        current_movie_list.extend(subsequent_movie_list)
    current_movie_list[current_movie_count - movie_count:] = movie_list

    with open(options.database, 'w') as db:
        print("saving {} movies to local database".format(len(current_movie_list)))
        json.dump(current_movie_list, db, sort_keys=True, indent=4)


def main():
    main_parser = ArgumentParser()
    main_parser.add_argument("-t", "--timeout", type=int, default=30, help="timeout for each single query in seconds")
    main_parser.add_argument("-d", "--database", help="explicit name of the database")

    subparsers = main_parser.add_subparsers(title="supported actions")
    subparsers.required = True
    subparsers.dest = "command"
    fetch_parser = subparsers.add_parser('fetch', help="fetch a whole copy of the movie database")
    fetch_parser.set_defaults(action=fetch)
    update_parser = subparsers.add_parser('update', help="incremental update an existing movie database")
    update_parser.set_defaults(action=update)

    for parser in (fetch_parser, update_parser):
        parser.add_argument("-q", "--quality", choices=["720p", "1080p", "3D"], default="1080p",
                            help="Used to filter by a given quality")
        parser.add_argument("-r", "--minimum_rating", type=int, choices=range(0, 10),
                            help="Used to filter movie by a given minimum IMDb rating")
        parser.add_argument("-g", "--genre",
                            help="Used to filter by a given genre (See http://www.imdb.com/genre/ for full list)")
        parser.add_argument("-t", "--query_term",
                            help="Used for movie search, matching on: Movie Title/IMDb Code, Actor Name/IMDb Code, Director Name/IMDb Code")

    options = main_parser.parse_args()

    query_parameters = {k: v for k, v in vars(options).items() if v}
    query_parameters["limit"] = 50

    argument_names = ["quality", "minimum_rating", "genre", "query_term"]
    database = options.database or "-".join(str(query_parameters[k]) for k in argument_names if k in query_parameters)
    database = path.join(path.dirname(__file__), "../var/db", "movies_{}.json".format(database))
    options.database = database

    loop = asyncio.get_event_loop()
    loop.run_until_complete(options.action(options, query_parameters))


if __name__ == "__main__":
    main()
